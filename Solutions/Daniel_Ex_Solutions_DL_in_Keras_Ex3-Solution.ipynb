{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9f1a661",
   "metadata": {},
   "source": [
    "<h1> Intro to Deep Learning - Keras </h1>\n",
    "<br>\n",
    "Keras is a powerful and easy-to-use free open source Python library for developing and evaluating deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29364d13",
   "metadata": {},
   "source": [
    "<h2> First Neural Network with Keras </h2>\n",
    "Eventually, this course does not focus in it, however one of the biggest challenges is within the Data.\n",
    "Here you will get a \"ready-to-go\" dataset, which will be used for NN training (with Keras).\n",
    "The main goal of the excersice is to get you familiar with the Keras API, so you will see how easy is to:\n",
    "<li>develop a DL model</li>\n",
    "<li>train it on some data</li>\n",
    "<li>evaluate the model's performance on some unseen data (aka test)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b334b",
   "metadata": {},
   "source": [
    "<h2> Data preprocessing </h2>\n",
    "<br>\n",
    "PIMA-Indians-Diabetes: The diagnostic, binary-valued variable investigated is whether the patient shows signs of diabetes according to World Health Organization criteria. \n",
    "<br>\n",
    "The population lives near Phoenix, Arizona, USA.\n",
    "<br>\n",
    "Each data point holds the below attributes (all numeric-valued):\n",
    "<ul>\n",
    "    <li>Number of times pregnant</li>\n",
    "    <li>Plasma glucose concentration a 2 hours in an oral glucose tolerance test</li>\n",
    "    <li>Diastolic blood pressure (mm Hg)</li>\n",
    "    <li>Triceps skin fold thickness (mm)</li>\n",
    "    <li>2-Hour serum insulin (mu U/ml)</li>\n",
    "    <li>Body mass index (weight in kg/(height in m)^2)</li>\n",
    "    <li>Diabetes pedigree function</li>\n",
    "    <li>Age (years)</li>\n",
    "    <li>Class variable (0 or 1)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be82277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import relevant libraries\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import layers\n",
    "import keras\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "# Data should be in numpy ndarray format\n",
    "# split into input (X) and output (y) variables\n",
    "# X - used as our vector of inputs, this is there the magic of the data comes in\n",
    "# y - used as our label. In this case, classification.\n",
    "# The goal of the task is to find an X->y mapping which we will be satisfied with (in terms of performance)\n",
    "X = dataset[:,:-1]\n",
    "y = dataset[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca086d24",
   "metadata": {},
   "source": [
    "<h2> DL Model using Keras </h2>\n",
    "<br>\n",
    "Here, we are using the Keras API.\n",
    "<br>\n",
    "TODO:\n",
    "<ul>\n",
    "    <li>1. You should define this architecture: Input: 8 -> Hidden: 12 -> Hidden: 8 -> Relu -> 1 -> Sigmoid </li>\n",
    "    <li> 2. The model should have a binary cross entropy loss, and its optimizer should be *adam*. </li>\n",
    "    <li> 3. The model should optimize towards <b>accuracy</b> </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b4be70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functional API Summary\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 8)]               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 12)                108       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Sequential API Summary\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 15:24:01.349999: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-11 15:24:01.350040: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# define the keras model. Here you can see two methods of it (both Keras APIs - Model/Func + Sequential)\n",
    "# Sequential\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Functional / Model\n",
    "inputs = keras.Input(shape=(8))\n",
    "x = layers.Dense(12, activation=\"relu\")(inputs)\n",
    "x = layers.Dense(8, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_b = keras.Model(inputs, outputs)\n",
    "\n",
    "print(\"Functional API Summary\")\n",
    "model_b.summary()\n",
    "print(\"Sequential API Summary\")\n",
    "model.summary()\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# This can be commented out, not relevant anymore\n",
    "# model_b.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94fc96b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: Find the function that prints the model architecture into the console\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd0305d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "77/77 [==============================] - 4s 9ms/step - loss: 17.3696 - accuracy: 0.6406\n",
      "Epoch 2/500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 5.2096 - accuracy: 0.5846\n",
      "Epoch 3/500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 2.1701 - accuracy: 0.5247\n",
      "Epoch 4/500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 1.4939 - accuracy: 0.5560\n",
      "Epoch 5/500\n",
      "77/77 [==============================] - 1s 14ms/step - loss: 1.2390 - accuracy: 0.5781\n",
      "Epoch 6/500\n",
      "77/77 [==============================] - 1s 12ms/step - loss: 1.0849 - accuracy: 0.6029\n",
      "Epoch 7/500\n",
      "77/77 [==============================] - 1s 13ms/step - loss: 0.9333 - accuracy: 0.5990\n",
      "Epoch 8/500\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 0.8387 - accuracy: 0.6211\n",
      "Epoch 9/500\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.7602 - accuracy: 0.6445\n",
      "Epoch 10/500\n",
      "77/77 [==============================] - 1s 19ms/step - loss: 0.7283 - accuracy: 0.6432\n",
      "Epoch 11/500\n",
      "77/77 [==============================] - 1s 15ms/step - loss: 0.6925 - accuracy: 0.6641\n",
      "Epoch 12/500\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 0.6592 - accuracy: 0.6667\n",
      "Epoch 13/500\n",
      "77/77 [==============================] - 1s 19ms/step - loss: 0.6545 - accuracy: 0.6784\n",
      "Epoch 14/500\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.6588 - accuracy: 0.6680\n",
      "Epoch 15/500\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 0.6466 - accuracy: 0.6680\n",
      "Epoch 16/500\n",
      "77/77 [==============================] - 1s 19ms/step - loss: 0.6296 - accuracy: 0.6797\n",
      "Epoch 17/500\n",
      "77/77 [==============================] - 1s 19ms/step - loss: 0.6155 - accuracy: 0.6979\n",
      "Epoch 18/500\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.6191 - accuracy: 0.6979\n",
      "Epoch 19/500\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.6233 - accuracy: 0.6966\n",
      "Epoch 20/500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.6233 - accuracy: 0.6823\n",
      "Epoch 21/500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.6087 - accuracy: 0.7096\n",
      "Epoch 22/500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.6321 - accuracy: 0.6966\n",
      "Epoch 23/500\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 0.6232 - accuracy: 0.6888\n",
      "Epoch 24/500\n",
      "77/77 [==============================] - 1s 14ms/step - loss: 0.6039 - accuracy: 0.6953\n",
      "Epoch 25/500\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.5964 - accuracy: 0.7031\n",
      "Epoch 26/500\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.6043 - accuracy: 0.6979\n",
      "Epoch 27/500\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.6100 - accuracy: 0.6979\n",
      "Epoch 28/500\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.5995 - accuracy: 0.7044\n",
      "Epoch 29/500\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.5769 - accuracy: 0.7096\n",
      "Epoch 30/500\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 0.5853 - accuracy: 0.7109\n",
      "Epoch 31/500\n",
      "77/77 [==============================] - 1s 13ms/step - loss: 0.5893 - accuracy: 0.7161\n",
      "Epoch 32/500\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.5917 - accuracy: 0.6992\n",
      "Epoch 33/500\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 0.5853 - accuracy: 0.7161\n",
      "Epoch 34/500\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.5913 - accuracy: 0.7031\n",
      "Epoch 35/500\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.5837 - accuracy: 0.7044\n",
      "Epoch 36/500\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.5729 - accuracy: 0.7214\n",
      "Epoch 37/500\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.5880 - accuracy: 0.6992\n",
      "Epoch 38/500\n",
      "77/77 [==============================] - 2s 20ms/step - loss: 0.5626 - accuracy: 0.7292\n",
      "Epoch 39/500\n",
      "77/77 [==============================] - 1s 14ms/step - loss: 0.5956 - accuracy: 0.6966\n",
      "Epoch 40/500\n",
      "77/77 [==============================] - 1s 15ms/step - loss: 0.5642 - accuracy: 0.7253\n",
      "Epoch 41/500\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.5739 - accuracy: 0.7253\n",
      "Epoch 42/500\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.5759 - accuracy: 0.7070\n",
      "Epoch 43/500\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.5603 - accuracy: 0.7253\n",
      "Epoch 44/500\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.5664 - accuracy: 0.7161\n",
      "Epoch 45/500\n",
      "77/77 [==============================] - 1s 13ms/step - loss: 0.5689 - accuracy: 0.7240\n",
      "Epoch 46/500\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.5653 - accuracy: 0.7070\n",
      "Epoch 47/500\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 0.5611 - accuracy: 0.7279\n",
      "Epoch 48/500\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.5744 - accuracy: 0.7018\n",
      "Epoch 49/500\n",
      "77/77 [==============================] - 1s 12ms/step - loss: 0.5580 - accuracy: 0.7383\n",
      "Epoch 50/500\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.5683 - accuracy: 0.7292\n",
      "Epoch 51/500\n",
      "77/77 [==============================] - 1s 19ms/step - loss: 0.5550 - accuracy: 0.7188\n",
      "Epoch 52/500\n",
      "77/77 [==============================] - 2s 19ms/step - loss: 0.5642 - accuracy: 0.7148\n",
      "Epoch 53/500\n",
      "77/77 [==============================] - 2s 27ms/step - loss: 0.5683 - accuracy: 0.7057\n",
      "Epoch 54/500\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.5582 - accuracy: 0.7135\n",
      "Epoch 55/500\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.5799 - accuracy: 0.7057\n",
      "Epoch 56/500\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.5426 - accuracy: 0.7357\n",
      "Epoch 57/500\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 0.5321 - accuracy: 0.7487\n",
      "Epoch 58/500\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.5559 - accuracy: 0.7292\n",
      "Epoch 59/500\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.5654 - accuracy: 0.7318\n",
      "Epoch 60/500\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.5498 - accuracy: 0.7240\n",
      "Epoch 61/500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.5519 - accuracy: 0.7448\n",
      "Epoch 62/500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.5311 - accuracy: 0.7474\n",
      "Epoch 63/500\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 0.5349 - accuracy: 0.7448\n",
      "Epoch 64/500\n",
      "77/77 [==============================] - 1s 7ms/step - loss: 0.5432 - accuracy: 0.7253\n",
      "Epoch 65/500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.5393 - accuracy: 0.7227\n",
      "Epoch 66/500\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.5639 - accuracy: 0.7161\n",
      "Epoch 67/500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.5237 - accuracy: 0.7331\n",
      "Epoch 68/500\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 0.5386 - accuracy: 0.7292\n",
      "Epoch 69/500\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 0.5430 - accuracy: 0.7396\n",
      "Epoch 70/500\n",
      "77/77 [==============================] - 1s 15ms/step - loss: 0.5463 - accuracy: 0.7383\n",
      "Epoch 71/500\n",
      "77/77 [==============================] - 1s 12ms/step - loss: 0.5361 - accuracy: 0.7461\n",
      "Epoch 72/500\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 0.5156 - accuracy: 0.7578\n",
      "Epoch 73/500\n",
      "77/77 [==============================] - 1s 15ms/step - loss: 0.5300 - accuracy: 0.7409\n",
      "Epoch 74/500\n",
      "77/77 [==============================] - 1s 14ms/step - loss: 0.5334 - accuracy: 0.7422\n",
      "Epoch 75/500\n",
      "77/77 [==============================] - 1s 11ms/step - loss: 0.5226 - accuracy: 0.7448\n",
      "Epoch 76/500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.5347 - accuracy: 0.7370\n",
      "Epoch 77/500\n",
      "77/77 [==============================] - 1s 12ms/step - loss: 0.5261 - accuracy: 0.7344\n",
      "Epoch 78/500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.5207 - accuracy: 0.7487\n",
      "Epoch 79/500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.5681 - accuracy: 0.7396\n",
      "Epoch 80/500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.5663 - accuracy: 0.7201\n",
      "Epoch 81/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.7370\n",
      "Epoch 82/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5256 - accuracy: 0.7357\n",
      "Epoch 83/500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.5199 - accuracy: 0.7474\n",
      "Epoch 84/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5156 - accuracy: 0.7578\n",
      "Epoch 85/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7513\n",
      "Epoch 86/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5076 - accuracy: 0.7552\n",
      "Epoch 87/500\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.5104 - accuracy: 0.7539\n",
      "Epoch 88/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5199 - accuracy: 0.7448\n",
      "Epoch 89/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7461\n",
      "Epoch 90/500\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5246 - accuracy: 0.7344\n",
      "Epoch 91/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5688 - accuracy: 0.7161\n",
      "Epoch 92/500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.5162 - accuracy: 0.7331\n",
      "Epoch 93/500\n",
      "77/77 [==============================] - 1s 8ms/step - loss: 0.5056 - accuracy: 0.7565\n",
      "Epoch 94/500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.5187 - accuracy: 0.7383\n",
      "Epoch 95/500\n",
      "77/77 [==============================] - 1s 6ms/step - loss: 0.5178 - accuracy: 0.7435\n",
      "Epoch 96/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5000 - accuracy: 0.7578\n",
      "Epoch 97/500\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.5221 - accuracy: 0.7500\n",
      "Epoch 98/500\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 0.4972 - accuracy: 0.7500\n",
      "Epoch 99/500\n",
      "77/77 [==============================] - 1s 9ms/step - loss: 0.5155 - accuracy: 0.7578\n",
      "Epoch 100/500\n",
      "77/77 [==============================] - 1s 10ms/step - loss: 0.5213 - accuracy: 0.7552\n",
      "Epoch 101/500\n",
      "77/77 [==============================] - 1s 14ms/step - loss: 0.5152 - accuracy: 0.7422\n",
      "Epoch 102/500\n",
      "77/77 [==============================] - 1s 13ms/step - loss: 0.5077 - accuracy: 0.7578\n",
      "Epoch 103/500\n",
      "77/77 [==============================] - 1s 17ms/step - loss: 0.5453 - accuracy: 0.7318\n",
      "Epoch 104/500\n",
      "77/77 [==============================] - 2s 29ms/step - loss: 0.5114 - accuracy: 0.7526\n",
      "Epoch 105/500\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 0.5067 - accuracy: 0.7539\n",
      "Epoch 106/500\n",
      "77/77 [==============================] - 1s 16ms/step - loss: 0.5264 - accuracy: 0.7422\n",
      "Epoch 107/500\n",
      "77/77 [==============================] - 1s 15ms/step - loss: 0.4988 - accuracy: 0.7539\n",
      "Epoch 108/500\n",
      "77/77 [==============================] - 1s 15ms/step - loss: 0.5013 - accuracy: 0.7578\n",
      "Epoch 109/500\n",
      "77/77 [==============================] - 2s 20ms/step - loss: 0.5088 - accuracy: 0.7552\n",
      "Epoch 110/500\n",
      "77/77 [==============================] - 1s 12ms/step - loss: 0.4956 - accuracy: 0.7487\n",
      "Epoch 111/500\n",
      "77/77 [==============================] - 1s 13ms/step - loss: 0.5013 - accuracy: 0.7565\n",
      "Epoch 112/500\n",
      "77/77 [==============================] - 2s 20ms/step - loss: 0.4998 - accuracy: 0.7591\n",
      "Epoch 113/500\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.4973 - accuracy: 0.7656\n",
      "Epoch 114/500\n",
      "77/77 [==============================] - 1s 18ms/step - loss: 0.4913 - accuracy: 0.7630\n",
      "Epoch 115/500\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.4917 - accuracy: 0.7604\n",
      "Epoch 116/500\n",
      "22/77 [=======>......................] - ETA: 1s - loss: 0.4572 - accuracy: 0.7909"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# fit the keras model on the dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Note: I've changed the number of epochs, wasn't neccesary as part of the excercise.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "# Note: I've changed the number of epochs, wasn't neccesary as part of the excercise.\n",
    "model.fit(X, y, epochs=100, batch_size=10, verbose=1)\n",
    "# make class predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de73ca62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 1 (expected 1)\n",
      "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
      "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 1 (expected 1)\n",
      "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
      "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 1 (expected 1)\n"
     ]
    }
   ],
   "source": [
    "# Convert probabilities to classes\n",
    "# Note: Using sigmoid, we get the output in this form, thus we need to decide on the prediction \"threshold\"\n",
    "threhsold = 0.5\n",
    "predictions = model.predict_on_batch(X)\n",
    "predictions = np.where(predictions > threhsold, 1, 0)\n",
    "# classes_x=np.argmax(predictions,axis=1)\n",
    "# summarize the first 5 cases\n",
    "for i in range(5):\n",
    "    print('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b98b2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       500\n",
      "           1       0.73      0.56      0.63       268\n",
      "\n",
      "    accuracy                           0.77       768\n",
      "   macro avg       0.76      0.72      0.74       768\n",
      "weighted avg       0.77      0.77      0.77       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "print(classification_report(y, predictions, target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfee735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
